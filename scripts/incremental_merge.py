#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import shutil
import sys
import csv
from datetime import datetime

# æ·»åŠ  scripts ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥å…¶ä»–æ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), 'scripts'))

import import_db_json
import export_db_json


def get_todo_new_files():
    """èŽ·å– todo/new ä¸­çš„æ–‡ä»¶åˆ—è¡¨"""
    new_files_dir = "./pretranslate_todo/todo/new"
    todo_files = []
    
    if os.path.exists(new_files_dir):
        for root, dirs, files in os.walk(new_files_dir):
            for file in files:
                if file.endswith("_translated.json"):
                    json_name = file[:-16] + ".json"
                    todo_files.append(json_name)
    
    return todo_files


def pretranslated_to_kv_files_single(root_dir: str, translated_file: str, json_filename: str):
    """å°†å•ä¸ªç¿»è¯‘æ–‡ä»¶è½¬æ¢ä¸º key-value æ ¼å¼"""
    temp_output = {}
    
    with open(translated_file, 'r', encoding='utf-8') as f:
        translated_data = json.load(f)  # æ—¥æ–‡: ä¸­æ–‡

    orig_file = os.path.join(root_dir, json_filename)
    if os.path.exists(orig_file):
        with open(orig_file, 'r', encoding='utf-8') as f:
            orig_data = json.load(f)  # key: æ—¥æ–‡

        for k, orig_jp in orig_data.items():
            temp_output[k] = translated_data.get(orig_jp, orig_jp)
    
    return temp_output


def incremental_merge():
    """
    å¢žé‡åˆå¹¶æµç¨‹ï¼š
    1. åªå¤„ç† todo/new ä¸­å­˜åœ¨çš„æ–‡ä»¶
    2. å¯¹è¿™äº›æ–‡ä»¶è¿›è¡Œä¼˜å…ˆçº§åˆå¹¶ï¼štodo/new > jp_cn > temp_key_cn(data)
    3. ç”Ÿæˆå†²çªæŠ¥å‘ŠCSV
    4. åªæ›´æ–°å¯¹åº”çš„ data æ–‡ä»¶
    """
    new_files_dir = "./pretranslate_todo/todo/new"
    old_trans_dir = "./pretranslate_todo/temp_key_cn"
    new_key_jp_dir = "./pretranslate_todo/temp_key_jp"
    jp_cn_dir = "./pretranslate_todo/jp_cn"
    output_dir = "./pretranslate_todo/merged"
    conflicts_dir = "./pretranslate_todo/conflicts"
    data_dir = "./data"
    gakumasu_json_dir = "./gakumasu-diff/json"

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    for dir_path in [output_dir, conflicts_dir]:
        if not os.path.isdir(dir_path):
            os.makedirs(dir_path)

    print("ðŸ”„ å¼€å§‹å¢žé‡åˆå¹¶æµç¨‹...")
    
    # 1. èŽ·å–éœ€è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    todo_files = get_todo_new_files()
    if not todo_files:
        print("âŒ todo/new ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ç¿»è¯‘æ–‡ä»¶ï¼Œæ— éœ€åˆå¹¶")
        return
    
    print(f"ðŸ“‹ å‘çŽ°éœ€è¦å¤„ç†çš„æ–‡ä»¶ ({len(todo_files)} ä¸ª):")
    for file in todo_files:
        print(f"  - {file}")
    
    print(f"\nðŸ“‹ ç¿»è¯‘ä¼˜å…ˆçº§ï¼štodo/new > jp_cn > temp_key_cn(data)")
    
    # 2. å¤„ç†æ¯ä¸ªæ–‡ä»¶
    all_conflicts = {}
    processed_files = []
    
    for json_filename in todo_files:
        print(f"\nðŸ“ å¤„ç†æ–‡ä»¶: {json_filename}")
        
        # æ–‡ä»¶è·¯å¾„
        todo_translated_file = os.path.join(new_files_dir, json_filename[:-5] + "_translated.json")
        old_key_cn_file = os.path.join(old_trans_dir, json_filename)
        new_key_jp_file = os.path.join(new_key_jp_dir, json_filename)
        jp_cn_file = os.path.join(jp_cn_dir, json_filename)
        output_file = os.path.join(output_dir, json_filename)
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(todo_translated_file):
            print(f"  âš ï¸  è·³è¿‡ {json_filename}ï¼šæ‰¾ä¸åˆ°å¯¹åº”çš„ç¿»è¯‘æ–‡ä»¶")
            continue
        
        if not os.path.exists(new_key_jp_file):
            print(f"  âš ï¸  è·³è¿‡ {json_filename}ï¼šæ‰¾ä¸åˆ°å¯¹åº”çš„ key-jp æ˜ å°„æ–‡ä»¶")
            continue
        
        # åŠ è½½ todo/new ç¿»è¯‘ï¼ˆè½¬æ¢ä¸º key-value æ ¼å¼ï¼‰
        print(f"  ðŸ“¥ åŠ è½½ todo/new ç¿»è¯‘...")
        todo_new_kv = pretranslated_to_kv_files_single(new_key_jp_dir, todo_translated_file, json_filename)
        print(f"    âœ… åŠ è½½äº† {len(todo_new_kv)} æ¡ç¿»è¯‘")
        
        # åŠ è½½å…¶ä»–æ•°æ®æº
        with open(new_key_jp_file, 'r', encoding='utf-8') as f:
            new_key_jp_data = json.load(f)  # key: jp æ˜ å°„
        
        # åŠ è½½æ—§ç¿»è¯‘ (æ¥è‡ªdata)
        old_key_cn_data = {}
        if os.path.exists(old_key_cn_file):
            with open(old_key_cn_file, 'r', encoding='utf-8') as f:
                old_key_cn_data = json.load(f)
        
        # åŠ è½½ jp_cn ç¿»è¯‘æ˜ å°„
        jp_cn_data = {}
        if os.path.exists(jp_cn_file):
            with open(jp_cn_file, 'r', encoding='utf-8') as f:
                jp_cn_data = json.load(f)
        
        # åˆå¹¶ç¿»è¯‘å¹¶è®°å½•å†²çª
        final_key_cn_data = {}
        conflicts = []
        
        todo_new_count = 0
        jp_cn_count = 0
        old_count = 0
        untranslated_count = 0
        conflict_count = 0
        
        for key, jp_value in new_key_jp_data.items():
            used_translation = None
            source = None
            
            # æ£€æŸ¥æ‰€æœ‰å¯ç”¨çš„ç¿»è¯‘æ¥æº
            available_translations = {}
            
            # todo/new ç¿»è¯‘ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
            if key in todo_new_kv and todo_new_kv[key] != jp_value:  # ç¡®ä¿ä¸æ˜¯æœªç¿»è¯‘çš„æ—¥æ–‡
                available_translations["todo/new"] = todo_new_kv[key]
            
            # jp_cn ç¿»è¯‘
            if jp_value in jp_cn_data:
                available_translations["jp_cn"] = jp_cn_data[jp_value]
            
            # data ç¿»è¯‘
            if key in old_key_cn_data and old_key_cn_data[key] != jp_value:  # ç¡®ä¿ä¸æ˜¯æœªç¿»è¯‘çš„æ—¥æ–‡
                available_translations["data"] = old_key_cn_data[key]
            
            # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©ç¿»è¯‘
            if "todo/new" in available_translations:
                used_translation = available_translations["todo/new"]
                source = "todo/new"
                todo_new_count += 1
            elif "jp_cn" in available_translations:
                used_translation = available_translations["jp_cn"]
                source = "jp_cn"
                jp_cn_count += 1
            elif "data" in available_translations:
                used_translation = available_translations["data"]
                source = "data"
                old_count += 1
            else:
                used_translation = jp_value
                source = "åŽŸæ–‡"
                untranslated_count += 1
            
            final_key_cn_data[key] = used_translation
            
            # è®°å½•å†²çªï¼ˆå¤šä¸ªæ¥æºæœ‰ä¸åŒç¿»è¯‘ï¼‰
            if len(available_translations) > 1:
                unique_translations = set(available_translations.values())
                if len(unique_translations) > 1:  # ç¡®å®žæœ‰ä¸åŒçš„ç¿»è¯‘
                    conflict_record = {
                        "é”®å": key,
                        "æ—¥æ–‡åŽŸæ–‡": jp_value,
                        "å½“å‰ä½¿ç”¨": used_translation,
                        "ä½¿ç”¨æ¥æº": source
                    }
                    
                    for src, trans in available_translations.items():
                        conflict_record[f"{src}_ç¿»è¯‘"] = trans
                    
                    conflicts.append(conflict_record)
                    conflict_count += 1
        
        # ä¿å­˜åˆå¹¶åŽçš„æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_key_cn_data, f, ensure_ascii=False, indent=4)
        
        print(f"    ðŸ“Š ç¿»è¯‘ç»Ÿè®¡: todo/new={todo_new_count}, jp_cn={jp_cn_count}, data={old_count}, æœªç¿»è¯‘={untranslated_count}")
        if conflict_count > 0:
            print(f"    âš ï¸  å‘çŽ°å†²çª: {conflict_count} ä¸ª")
        
        # è®°å½•å†²çªå’Œå¤„ç†çš„æ–‡ä»¶
        if conflicts:
            all_conflicts[json_filename] = conflicts
        
        processed_files.append(json_filename)
        print(f"    âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {json_filename}")
    
    # 3. ç”Ÿæˆå†²çªæŠ¥å‘ŠCSV
    if all_conflicts:
        print(f"\nðŸ“‹ ç”Ÿæˆå†²çªæŠ¥å‘Š...")
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        conflicts_csv = os.path.join(conflicts_dir, f"incremental_conflicts_{timestamp}.csv")
        
        with open(conflicts_csv, 'w', encoding='utf-8-sig', newline='') as csvfile:
            fieldnames = ["æ–‡ä»¶å", "é”®å", "æ—¥æ–‡åŽŸæ–‡", "å½“å‰ä½¿ç”¨", "ä½¿ç”¨æ¥æº", "todo/new_ç¿»è¯‘", "jp_cn_ç¿»è¯‘", "data_ç¿»è¯‘"]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            total_conflicts = 0
            for file_name, conflicts in all_conflicts.items():
                for conflict in conflicts:
                    row = {
                        "æ–‡ä»¶å": file_name,
                        "é”®å": conflict.get("é”®å", ""),
                        "æ—¥æ–‡åŽŸæ–‡": conflict.get("æ—¥æ–‡åŽŸæ–‡", ""),
                        "å½“å‰ä½¿ç”¨": conflict.get("å½“å‰ä½¿ç”¨", ""),
                        "ä½¿ç”¨æ¥æº": conflict.get("ä½¿ç”¨æ¥æº", ""),
                        "todo/new_ç¿»è¯‘": conflict.get("todo/new_ç¿»è¯‘", ""),
                        "jp_cn_ç¿»è¯‘": conflict.get("jp_cn_ç¿»è¯‘", ""),
                        "data_ç¿»è¯‘": conflict.get("data_ç¿»è¯‘", "")
                    }
                    writer.writerow(row)
                    total_conflicts += 1
        
        print(f"  âœ… å†²çªæŠ¥å‘Šå·²ç”Ÿæˆ: {conflicts_csv}")
        print(f"  ðŸ“Š å…±å‘çŽ° {total_conflicts} ä¸ªç¿»è¯‘å†²çª")
        print(f"  ðŸ’¡ è¯·å®¡æ ¸ CSV æ–‡ä»¶ä¸­çš„å†²çªï¼Œå¹¶å†³å®šä½¿ç”¨å“ªä¸ªç¿»è¯‘ç‰ˆæœ¬")
    else:
        print(f"\nðŸŽ‰ æœªå‘çŽ°ç¿»è¯‘å†²çªï¼")
    
    if not processed_files:
        print("\nâŒ æ²¡æœ‰æ–‡ä»¶è¢«å¤„ç†ï¼Œåˆå¹¶æ“ä½œç»“æŸ")
        return
    
    print(f"\nâœ… å¢žé‡åˆå¹¶å®Œæˆï¼")
    print(f"ðŸ“ å¤„ç†çš„æ–‡ä»¶: {len(processed_files)} ä¸ª")
    print(f"ðŸ“ åˆå¹¶ç»“æžœä¿å­˜åœ¨: {output_dir}")
    
    # 4. è¯¢é—®æ˜¯å¦ç»§ç»­æ‰§è¡Œå¢žé‡å¯¼å…¥
    user_input = input("\nðŸš€ æ˜¯å¦ç»§ç»­æ‰§è¡Œå¢žé‡å¯¼å…¥ï¼Œå°†ç¿»è¯‘æ›´æ–°åˆ° data æ–‡ä»¶å¤¹ï¼Ÿ(y/N): ").lower().strip()
    if user_input in ['y', 'yes']:
        print("ðŸ“¤ å¼€å§‹å¢žé‡å¯¼å…¥ç¿»è¯‘åˆ° data æ–‡ä»¶å¤¹...")
        
        # åªå¯¼å…¥å¤„ç†è¿‡çš„æ–‡ä»¶
        for json_filename in processed_files:
            base_file = os.path.join(gakumasu_json_dir, json_filename)
            translated_file = os.path.join(output_dir, json_filename)
            output_file = os.path.join(data_dir, json_filename)
            
            if os.path.exists(base_file) and os.path.exists(translated_file):
                import_db_json.import_main(base_file, translated_file, output_file)
                print(f"  âœ… æ›´æ–°: {json_filename}")
            else:
                print(f"  âš ï¸  è·³è¿‡ {json_filename}ï¼šç¼ºå°‘å¿…è¦æ–‡ä»¶")
        
        print("âœ… å¢žé‡å¯¼å…¥å®Œæˆï¼")
    else:
        print("â¸ï¸  è·³è¿‡å¯¼å…¥æ­¥éª¤")
        print(f"ðŸ’¡ å¦‚éœ€æ‰‹åŠ¨å¯¼å…¥ç‰¹å®šæ–‡ä»¶ï¼Œè¯·è¿è¡Œï¼š")
        print(f"   python scripts/import_db_json.py")
    
    # 5. æ˜¾ç¤ºæ‘˜è¦
    print(f"\nðŸ“‹ æ“ä½œæ‘˜è¦:")
    print(f"   - å¤„ç†æ–‡ä»¶æ•°: {len(processed_files)}")
    print(f"   - å†²çªæ–‡ä»¶æ•°: {len(all_conflicts)}")
    print(f"   - å¤„ç†çš„æ–‡ä»¶: {', '.join(processed_files[:5])}" + ("..." if len(processed_files) > 5 else ""))


if __name__ == '__main__':
    incremental_merge()
